{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A collection of Terraform modules for provisioning resources in the cloud.</p>"},{"location":"aws/github_action_oidc/","title":"GitHub Action OIDC","text":"<p>This module configures an OpenID Connect (OIDC) provider for GitHub Actions on AWS. It enables GitHub Actions to authenticate with AWS using OIDC tokens, enhancing security by removing the need for long-lived AWS credentials.</p>"},{"location":"aws/github_action_oidc/#benefits-of-using-oidc-with-github-actions","title":"Benefits of Using OIDC with GitHub Actions","text":"<p>Implementing OIDC with GitHub Actions offers a secure method for authenticating workflows with AWS. It minimizes the risk of credential exposure and simplifies secret management. For additional details, refer to the following resources:</p> <ul> <li>Configuring OpenID Connect in Amazon Web Services</li> <li>GitHub Actions: Update on OIDC integration with AWS</li> </ul>"},{"location":"aws/github_action_oidc/#example-github-action-workflow","title":"Example Github Action Workflow","text":"<pre><code>name: Example OIDC Workflow\n\non:\n  pull_request:\n    branches:\n      - main\n\npermissions:\n  id-token: write  # Required for requesting the Json Web Token (JWT)\n  contents: read   # Required for actions/checkout\n\njobs:\n  example-job:\n    name: Example Job\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        id: checkout-repo\n        uses: actions/checkout@v4\n\n      - name: Configure AWS credentials from OIDC\n        id: configure-aws-credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          audience: sts.amazonaws.com\n          aws-region: ${{ secrets.AWS_REGION }}  # Set the AWS region as a repository secret\n          role-to-assume: ${{ secrets.AWS_GITHUB_ACTIONS_ROLE_ARN }}  # Set the role ARN as a repository secret\n          role-session-name: example-session\n\n      - name: Add profile credentials to ~/.aws/credentials\n        id: add-profile-credentials\n        run: |\n          aws configure set aws_access_key_id ${{ env.AWS_ACCESS_KEY_ID }} --profile example_profile\n          aws configure set aws_secret_access_key ${{ env.AWS_SECRET_ACCESS_KEY }} --profile example_profile\n          aws configure set aws_session_token ${{ env.AWS_SESSION_TOKEN }} --profile example_profile\n</code></pre>"},{"location":"aws/optuna_sagemaker_studio/","title":"Optuna with SageMaker Studio","text":"<p>Sets up an environment for running hyperparameter optimization (HPO) with Optuna on Amazon SageMaker Studio.</p> <p>The configuration files and scripts are adapted from an AWS blog post and its associated GitHub repository.</p> <p>Additionally, it incorporates lifecycle script for setting up <code>sagemaker-code-editor</code> in SageMaker Studio.</p>"},{"location":"aws/optuna_sagemaker_studio/#overview","title":"Overview","text":"<pre><code>\u251c\u2500\u2500 backend.hcl-example            # Example configuration for Terraform backend\n\u251c\u2500\u2500 ecr.tf                         # Creates an Elastic Container Registry for Docker images used for training, preprocessing, or serving\n\u251c\u2500\u2500 iam.tf                         # IAM roles and policies for SageMaker and related services\n\u251c\u2500\u2500 lifecycle_scripts              # Lifecycle scripts for installing and configuring code-server\n\u2502   \u251c\u2500\u2500 install_codeserver.sh      # Script to install code-server\n\u2502   \u2514\u2500\u2500 setup_codeserver.sh        # Script to configure code-server during startup\n\u251c\u2500\u2500 main.tf                        # Main Terraform configuration file\n\u251c\u2500\u2500 outputs.tf                     # Outputs for the Terraform module\n\u251c\u2500\u2500 rds.tf                         # RDS configuration for databases\n\u251c\u2500\u2500 s3.tf                          # S3 bucket configuration for storage\n\u251c\u2500\u2500 sagemaker.tf                   # SageMaker configurations for running HPO\n\u251c\u2500\u2500 secrets_manager.tf             # Secrets Manager for handling sensitive information\n\u251c\u2500\u2500 security_groups.tf             # Security groups for network access\n\u251c\u2500\u2500 variables.tf                   # Variable definitions\n\u251c\u2500\u2500 variables.tfvars-example       # Example of variable values\n\u2514\u2500\u2500 vpc.tf                         # VPC configuration\n</code></pre>"},{"location":"aws/optuna_sagemaker_studio/#lifecycle-script","title":"Lifecycle Script","text":"<p>This lifecycle script shows examples for the following:</p> <p>Installation</p> <ul> <li>Tools into the <code>base</code> conda environment</li> <li>Python dependency management tools <code>poetry</code>, <code>uv</code>, and <code>pdm</code></li> <li>Extensions for <code>sagemaker-code-editor</code></li> </ul> <p>Configuration</p> <ul> <li>Configurations for <code>conda</code> and <code>git</code></li> <li>Keyboard shortcuts and settings for <code>sagemaker-code-editor</code></li> </ul> <p>References</p> <ul> <li>External library and kernel installation</li> <li>Create a lifecycle configuration to install Code Editor extensions</li> <li>Code Editor in Amazon SageMaker Studio</li> </ul>"},{"location":"aws/optuna_sagemaker_studio/#modules","title":"Modules","text":""},{"location":"aws/optuna_sagemaker_studio/#1-vpctf","title":"1. <code>vpc.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>VPC: Defines a Virtual Private Cloud (VPC) for network isolation.</li> <li>Subnets: Creates public and private subnets for resource placement.</li> <li>Internet Gateway: Enables internet access for public subnets.</li> <li>NAT Gateways: Provides internet access for private subnets.</li> <li>Route Tables: Manages routing within the VPC for public and private subnets.</li> </ul> <p>Dependencies:</p> <ul> <li>Other resources, such as RDS and SageMaker, rely on the VPC and its subnets for network configuration.</li> <li>Security groups (from <code>security_groups.tf</code>) are tied to this VPC.</li> </ul>"},{"location":"aws/optuna_sagemaker_studio/#2-security_groupstf","title":"2. <code>security_groups.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>SageMaker Security Group: Allows outbound internet access for SageMaker Studio.</li> </ul> <p>Dependencies:</p> <ul> <li>Used by resources in <code>sagemaker.tf</code> for network access control.</li> </ul>"},{"location":"aws/optuna_sagemaker_studio/#3-secrets_managertf","title":"3. <code>secrets_manager.tf</code>","text":"<p>Note: As of 2025, code repository integration is only supported for JupyterLab and JupyterServer apps, not the Code Editor in SageMaker Studio. Additionally, private repositories are not yet supported. Therefore, this secret remains unused in the current configuration. Repository must be cloned manually using this secret if needed.</p> <p>Provisioned Resources:</p> <ul> <li>Secrets: Manages sensitive data such as:</li> <li>GitHub Personal Access Token for SageMaker's code repository.</li> <li>RDS credentials for database access.</li> <li>Random String/Password: Generates unique identifiers and secure passwords.</li> </ul> <p>Dependencies:</p> <ul> <li>Secrets are referenced by the SageMaker code repository (<code>sagemaker.tf</code>) and RDS cluster (<code>rds.tf</code>).</li> <li>RDS uses the credentials stored in Secrets Manager for secure access.</li> </ul>"},{"location":"aws/optuna_sagemaker_studio/#4-sagemakertf","title":"4. <code>sagemaker.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>SageMaker Domain: Creates the Studio domain with IAM authentication and public internet access.</li> <li>User Profile: Configures a named user profile with specific execution roles and security settings.</li> <li>SageMaker Space: Sets up a \"private\" space within the domain.</li> <li>Lifecycle Configuration: Defines a Code Editor lifecycle configuration using the setup script.</li> </ul> <p>Key Design:</p> <ul> <li>Docker access is enabled for container development.</li> <li>Code Editor app settings with specified instance types.</li> <li>EBS storage configuration with default and maximum volume sizes.</li> <li>Auto-mounting of EFS home directories.`</li> </ul> <p>Dependencies:</p> <ul> <li>Depends on IAM roles (<code>iam.tf</code>), public subnets (<code>vpc.tf</code>), security groups (<code>security_groups.tf</code>), and Secrets Manager secrets (<code>secrets_manager.tf</code>).</li> </ul> <p>References</p> <ul> <li>Amazon SageMaker AI domain overview</li> <li>Amazon SageMaker domain user profiles</li> <li>Connect your local Visual Studio Code to SageMaker spaces with remote access</li> <li>Amazon SageMaker Studio spaces</li> <li>Amazon EFS auto-mounting in Studio</li> </ul>"},{"location":"aws/optuna_sagemaker_studio/#5-s3tf","title":"5. <code>s3.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>S3 Bucket: Provides storage for datasets, artifacts, and outputs.</li> </ul> <p>Dependencies:</p> <ul> <li>The IAM role (<code>iam.tf</code>) grants permissions to SageMaker Studio for accessing this bucket.</li> </ul>"},{"location":"aws/optuna_sagemaker_studio/#6-iamtf","title":"6. <code>iam.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>SageMaker Execution Role: Creates an IAM role that SageMaker can assume to access AWS resources.</li> <li>Custom IAM Policies:</li> <li>S3 Policy: Grants full access to the specified S3 bucket.</li> <li>Remote Access Policy: Enables SageMaker remote access feature.</li> <li>Policy Attachments: Attaches the following policies to the SageMaker execution role:</li> <li>S3 Policy: Grants access to the S3 bucket created in <code>s3.tf</code> and the external S3 bucket used for Terraform remote state</li> <li>Remote Access Policy: Grants <code>sagemaker:StartSession</code> permission to enable remote access to SageMaker Studio compute instances</li> <li><code>AmazonSageMakerFullAccess</code> (AWS managed policy)</li> <li><code>AmazonEC2ContainerRegistryFullAccess</code> (AWS managed policy)</li> <li><code>SecretsManagerReadWrite</code> (AWS managed policy)</li> </ul> <p>Dependencies:</p> <ul> <li>SageMaker Studio user assumes this execution role to interact with S3, ECR, Secrets Manager, and other AWS services.</li> <li>The role is referenced in the SageMaker domain, user profiles, and for accessing S3 buckets.</li> </ul>"},{"location":"aws/optuna_sagemaker_studio/#7-ecrtf","title":"7. <code>ecr.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>ECR Repository: Creates an Elastic container registry repository for storing Docker images.</li> <li>Lifecycle Policy: Configures automatic cleanup of images with two rules:</li> <li>Retains only the most recent images tagged as \"latest\"</li> <li>Expires untagged images after a specified number of days</li> </ul> <p>Dependencies:</p> <ul> <li>The IAM role in <code>iam.tf</code> grants SageMaker permission to pull images from this repository.</li> <li>Used to store custom training, processing, or inference images.</li> </ul>"},{"location":"aws/optuna_sagemaker_studio/#8-rdstf","title":"8. <code>rds.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>Subnet Group: Defines subnets where RDS instances are deployed.</li> <li>Parameter Groups: Configures database engine settings.</li> <li>RDS Cluster: Creates a database cluster for storing HPO results.</li> <li>RDS Instances: Adds instances to the database cluster for handling workloads.</li> </ul> <p>Dependencies:</p> <ul> <li>Depends on private subnets from <code>vpc.tf</code> for deployment.</li> <li>Uses Secrets Manager credentials (<code>secrets_manager.tf</code>) for database access.</li> <li>The security group (<code>security_groups.tf</code>) controls access between SageMaker and RDS.</li> </ul>"},{"location":"aws/s3_remote_state/","title":"S3 Remote State","text":"<p>This module is based the following Stack Overflow answer and sets up an S3 bucket and a DynamoDB table for managing Terraform remote state storage and locking.</p> <p>In collaborative projects, storing the Terraform state file locally can lead to conflicts, inconsistencies, and even data loss. A remote backend, such as an S3 bucket, provides a centralized location for the state file.</p> <p>While this module does not fully resolve the \"chicken-and-egg\" problem of initial state management\u2014 since a local state file is still used for this initial setup\u2014 it provides a simple and effective way to create an S3 bucket for storing state files for all subsequent resources. This approach minimizes project complexity while enabling the use of remote state management.</p> <ol> <li> <p>S3 Remote State Backend</p> <ul> <li>Stores the Terraform state securely in an S3 bucket.</li> <li>Enables versioning to track state file changes over time.</li> <li>Includes a <code>prevent_destroy</code> lifecycle rule to avoid accidental deletion.</li> </ul> </li> <li> <p>DynamoDB State Locking</p> <ul> <li>Prevents concurrent state updates with a DynamoDB table for locking.</li> <li>Supports both <code>PAY_PER_REQUEST</code> and <code>PROVISIONED</code> billing modes, which can be controlled using the <code>dynamodb_table_billing_mode</code> variable.</li> </ul> </li> </ol>"},{"location":"aws/sagemaker_studio/","title":"SageMaker Studio","text":"<p>As of 2025, the project behind setting up code-server is effectively archived (last release was 2023). For a more modern setup with active development, see the setup for Sagemaker Studio.</p> <p>This setup can be used for running SageMaker Studio with a simple network infrastructure, security configurations, and minimal IAM. The configuration files provide the essential components needed to deploy a VPC, core Sagemaker resources (e.g., domain, user profile, space, lifecycle configuration), S3 for storage, and ECR repository for docker images.</p> <p>For a setup that integrates <code>optuna</code> for hyperparameter optimization, refer to the Optuna SageMaker Studio documentation.</p> <pre><code>\u251c\u2500\u2500 backend.hcl-example            # Example configuration for Terraform backend\n\u251c\u2500\u2500 ecr.tf                         # Elastic Container Registry for custom Docker images\n\u251c\u2500\u2500 iam.tf                         # IAM roles and policies for SageMaker Studio\n\u251c\u2500\u2500 lifecycle_scripts              # Lifecycle scripts for configuring SageMaker Studio\n\u2502   \u2514\u2500\u2500 setup_coder_editor.sh      # Script to configure the code editor environment\n\u251c\u2500\u2500 main.tf                        # Main Terraform configuration file\n\u251c\u2500\u2500 s3.tf                          # S3 bucket configuration\n\u251c\u2500\u2500 sagemaker.tf                   # SageMaker Studio configurations\n\u251c\u2500\u2500 secrets_manager.tf             # Secrets Manager for sensitive information\n\u251c\u2500\u2500 security_groups.tf             # Security groups for SageMaker Studio\n\u251c\u2500\u2500 variables.tf                   # Variable definitions\n\u251c\u2500\u2500 variables.tfvars-example       # Example variable values\n\u2514\u2500\u2500 vpc.tf                         # VPC configuration\n</code></pre>"},{"location":"aws/sagemaker_studio/#lifecycle-script","title":"Lifecycle Script","text":"<p>This lifecycle script shows examples for the following:</p> <p>Installation</p> <ul> <li>Tools into the <code>base</code> conda environment</li> <li>Python dependency management tools <code>poetry</code>, <code>uv</code>, and <code>pdm</code></li> <li>Extensions for <code>sagemaker-code-editor</code></li> </ul> <p>Configuration</p> <ul> <li>Configurations for <code>conda</code> and <code>git</code></li> <li>Keyboard shortcuts and settings for <code>sagemaker-code-editor</code></li> </ul> <p>References</p> <ul> <li>External library and kernel installation</li> <li>Create a lifecycle configuration to install Code Editor extensions</li> <li>Code Editor in Amazon SageMaker Studio</li> </ul>"},{"location":"aws/sagemaker_studio/#modules","title":"Modules","text":""},{"location":"aws/sagemaker_studio/#1-vpctf","title":"1. <code>vpc.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>VPC: Defines a Virtual Private Cloud (VPC) for network isolation with DNS support enabled.</li> <li>Public Subnets: Dynamically creates public subnets across two availability zones.</li> <li>Internet Gateway: Enables internet access for public subnets.</li> <li>Route Tables: Configures routing for public subnets with default routes to the internet gateway.</li> </ul> <p>Key Design:</p> <ul> <li>Uses dynamic subnet CIDR allocation based on the VPC CIDR block.</li> <li>Automatically selects availability zones with \"opt-in-not-required\" status.</li> </ul> <p>Dependencies:</p> <ul> <li>Provides networking for SageMaker Studio and other resources.</li> <li>Security groups (from <code>security_groups.tf</code>) are tied to this VPC.</li> </ul>"},{"location":"aws/sagemaker_studio/#2-security_groupstf","title":"2. <code>security_groups.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>SageMaker Security Group: Allows outbound internet access for SageMaker Studio.</li> </ul> <p>Dependencies:</p> <ul> <li>Used by resources in <code>sagemaker.tf</code> for network access control.</li> </ul>"},{"location":"aws/sagemaker_studio/#3-secrets_managertf","title":"3. <code>secrets_manager.tf</code>","text":"<p>Note: As of 2025, code repository integration is only supported for JupyterLab and JupyterServer apps, not the Code Editor in SageMaker Studio. Additionally, private repositories are not yet supported. Therefore, this secret remains unused in the current configuration. Repository must be cloned manually using this secret if needed.</p> <p>Provisioned Resources:</p> <ul> <li>Secrets: GitHub Personal Access Token for GitHub repository.</li> </ul>"},{"location":"aws/sagemaker_studio/#4-sagemakertf","title":"4. <code>sagemaker.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>SageMaker Domain: Creates the Studio domain with IAM authentication and public internet access.</li> <li>User Profile: Configures a named user profile with specific execution roles and security settings.</li> <li>SageMaker Space: Sets up a \"private\" space within the domain.</li> <li>Lifecycle Configuration: Defines a Code Editor lifecycle configuration using the setup script.</li> </ul> <p>Key Design:</p> <ul> <li>Docker access is enabled for container development.</li> <li>Code Editor app settings with specified instance types.</li> <li>EBS storage configuration with default and maximum volume sizes.</li> <li>Auto-mounting of EFS home directories.</li> </ul> <p>Dependencies:</p> <ul> <li>Depends on IAM roles (<code>iam.tf</code>), public subnets (<code>vpc.tf</code>), security groups (<code>security_groups.tf</code>), and Secrets Manager secrets (<code>secrets_manager.tf</code>).</li> </ul> <p>References</p> <ul> <li>Amazon SageMaker AI domain overview</li> <li>Amazon SageMaker domain user profiles</li> <li>Connect your local Visual Studio Code to SageMaker spaces with remote access</li> <li>Amazon SageMaker Studio spaces</li> <li>Amazon EFS auto-mounting in Studio</li> </ul>"},{"location":"aws/sagemaker_studio/#5-s3tf","title":"5. <code>s3.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>S3 Bucket: Provides storage for datasets, artifacts, and outputs.</li> </ul> <p>Dependencies:</p> <ul> <li>The IAM role (<code>iam.tf</code>) grants permissions to SageMaker Studio for accessing this bucket.</li> </ul>"},{"location":"aws/sagemaker_studio/#6-iamtf","title":"6. <code>iam.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>SageMaker Execution Role: Creates an IAM role that SageMaker can assume to access AWS resources.</li> <li>Custom IAM Policies:</li> <li>S3 Policy: Grants full access to the specified S3 bucket.</li> <li>Remote Access Policy: Enables SageMaker remote access feature.</li> <li>Policy Attachments: Attaches the following policies to the SageMaker execution role:</li> <li>S3 Policy: Grants access to the S3 bucket created in <code>s3.tf</code> and the external S3 bucket used for Terraform remote state</li> <li>Remote Access Policy: Grants <code>sagemaker:StartSession</code> permission to enable remote access to SageMaker Studio compute instances</li> <li><code>AmazonSageMakerFullAccess</code> (AWS managed policy)</li> <li><code>AmazonEC2ContainerRegistryFullAccess</code> (AWS managed policy)</li> <li><code>SecretsManagerReadWrite</code> (AWS managed policy)</li> </ul> <p>Dependencies:</p> <ul> <li>SageMaker Studio user assumes this execution role to interact with S3, ECR, Secrets Manager, and other AWS services.</li> <li>The role is referenced in the SageMaker domain, user profiles, and for accessing S3 buckets.</li> </ul>"},{"location":"aws/sagemaker_studio/#7-ecrtf","title":"7. <code>ecr.tf</code>","text":"<p>Provisioned Resources:</p> <ul> <li>ECR Repository: Creates an Elastic container registry repository for storing Docker images.</li> <li>Lifecycle Policy: Configures automatic cleanup of images with two rules:</li> <li>Retains only the most recent images tagged as \"latest\"</li> <li>Expires untagged images after a specified number of days</li> </ul> <p>Dependencies:</p> <ul> <li>The IAM role in <code>iam.tf</code> grants SageMaker permission to pull images from this repository.</li> <li>Used to store custom training, processing, or inference images.</li> </ul>"},{"location":"aws/terraform_lockfile_cross_platform/","title":"Terraform Lock File Cross-Platform Issues","text":""},{"location":"aws/terraform_lockfile_cross_platform/#problem","title":"Problem","text":"<p>When running Terraform workflows in CI/CD (e.g., GitHub Actions on Linux) after committing a <code>.terraform.lock.hcl</code> file generated locally on a different platform, e.g., macOS (Apple Silicon), validation using <code>terraform validate</code> may fail with an error like:</p> <pre><code>Error: registry.terraform.io/hashicorp/aws: the cached package for registry.terraform.io/hashicorp/aws 6.10.0 (in .terraform/providers) does not match any of the checksums recorded in the dependency lock file\n</code></pre> <p>This happens when the lock file only contains provider checksums for the local platform (e.g., <code>darwin_arm64</code>), but the CI runner requires Linux builds.</p>"},{"location":"aws/terraform_lockfile_cross_platform/#explanation","title":"Explanation","text":"<ul> <li> <p>Terraform lock files (<code>.terraform.lock.hcl</code>) store checksums of provider binaries per platform.</p> </li> <li> <p>By default, <code>terraform init</code> records checksums for the current system only.</p> </li> <li> <p>If we generate the lock file on macOS (<code>darwin_arm64</code>) and commit it, a Linux runner (<code>linux_amd64</code>) will download different provider binaries. Since the lock file lacks Linux checksums, Terraform refuses to proceed with <code>validate</code> or <code>plan</code> under <code>terraform init -lockfile=readonly</code>.</p> </li> <li> <p>If we ran <code>terraform init</code> without <code>-lockfile=readonly</code>, Terraform would silently re-lock based on the runner\u2019s platform, masking the mismatch.</p> </li> </ul>"},{"location":"aws/terraform_lockfile_cross_platform/#how-to-avoid","title":"How to Avoid","text":"<ol> <li>Generate multi-platform lock files before committing:</li> </ol> <pre><code>terraform providers lock -platform=linux_amd64 -platform=linux_arm64 -platform=darwin_amd64 -platform=darwin_arm64\n</code></pre> <p>This ensures the lock file contains checksums for both macOS and Linux runners.</p> <ol> <li> <p>Commit the updated <code>.terraform.lock.hcl</code> to the remote repository.</p> </li> <li> <p>In CI/CD pipelines:</p> </li> <li> <p>Use <code>terraform init -lockfile=readonly</code> to enforce reproducibility.</p> </li> <li>Only use <code>terraform init -upgrade</code> when intentionally bumping provider versions.</li> </ol> <p>By following these steps, Terraform will validate and run consistently across both local and CI environments without checksum mismatches.</p>"}]}